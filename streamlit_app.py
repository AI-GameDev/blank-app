"""
Streamlit + LangChain summarizer using GPT-4o-mini

Quick start (in a fresh environment):
    pip install --upgrade streamlit langchain langchain-openai tiktoken

Run:
    streamlit run streamlit_langchain_gpt4o_mini_summarizer.py

Notes:
- Your OpenAI API key is entered in the sidebar. It is NOT persisted.
- Model default is `gpt-4o-mini`, adjustable in the sidebar.
- Short texts use a single-pass prompt; long texts use map-reduce summarization.
"""

import os
import textwrap
from typing import List

import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema import HumanMessage, SystemMessage
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document
from langchain.chains.summarize import load_summarize_chain

APP_TITLE = "ğŸ“ LangChain Summarizer (GPT-4o-mini)"
DEFAULT_MODEL = "gpt-4o-mini"

# -----------------------------
# Utility: Build single-pass chain
# -----------------------------
def build_single_pass_chain(llm: ChatOpenAI, tone: str, length: str, language: str):
    """Return a function that takes raw text -> summary (single prompt)."""
    length_directive = {
        "ì§§ê²Œ": "Keep it concise (2-3 sentences).",
        "ë³´í†µ": "Aim for a medium-length summary (4-7 sentences).",
        "ê¸¸ê²Œ": "Provide a detailed summary (8-12 sentences).",
    }[length]

    system = f"""
You are a helpful expert summarizer. Summarize the user's text in {language}.
Use a {tone} tone. {length_directive}
- Preserve key facts, entities, and numerical details.
- Avoid redundancy and personal opinions.
- Output only the summary, no preamble.
""".strip()

    prompt = ChatPromptTemplate.from_messages([
        ("system", system),
        ("human", "{input_text}")
    ])

    def run(text: str) -> str:
        chain = prompt | llm
        resp = chain.invoke({"input_text": text})
        return resp.content

    return run


# -----------------------------
# Utility: Build map-reduce chain for long inputs
# -----------------------------
def build_map_reduce_chain(llm: ChatOpenAI, tone: str, length: str, language: str):
    """LangChain's load_summarize_chain(map_reduce) on Documents."""
    length_directive = {
        "ì§§ê²Œ": "Keep it concise (bullet points or 2-3 sentences).",
        "ë³´í†µ": "Aim for a medium-length summary (4-7 sentences).",
        "ê¸¸ê²Œ": "Provide a detailed summary (8-12 sentences).",
    }[length]

    map_prompt = ChatPromptTemplate.from_messages([
        ("system", f"Summarize the following chunk in {language} with a {tone} tone. {length_directive} Output only the summary."),
        ("human", "{text}")
    ])

    combine_prompt = ChatPromptTemplate.from_messages([
        ("system", f"Combine the chunk summaries into a single cohesive summary in {language}. Maintain a {tone} tone and {length_directive} Avoid repetition."),
        ("human", "{text}")
    ])

    chain = load_summarize_chain(
        llm,
        chain_type="map_reduce",
        map_prompt=map_prompt,
        combine_prompt=combine_prompt,
        return_intermediate_steps=False,
        verbose=False,
    )

    def run(docs: List[Document]) -> str:
        out = chain.invoke({"input_documents": docs})
        return out["output_text"]

    return run


# -----------------------------
# Streamlit UI
# -----------------------------
st.set_page_config(page_title=APP_TITLE, page_icon="ğŸ“", layout="wide")
st.title(APP_TITLE)

with st.sidebar:
    st.header("ğŸ” OpenAI ì„¤ì •")
    api_key = st.text_input("OpenAI API Key", type="password", placeholder="sk-...", help="í‚¤ëŠ” ì„¸ì…˜ ë™ì•ˆë§Œ ì‚¬ìš©ë˜ë©° ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    st.header("âš™ï¸ ëª¨ë¸ & íŒŒë¼ë¯¸í„°")
    model_name = st.text_input("Model", value=DEFAULT_MODEL, help="ì˜ˆ: gpt-4o-mini, gpt-4o, o3-mini ë“±")
    temperature = st.slider("Temperature", 0.0, 1.0, 0.3, 0.05)

    st.header("ğŸ§­ ìš”ì•½ ì˜µì…˜")
    tone = st.selectbox("í†¤", ["ì¤‘ë¦½ì ", "ê³µì‹ì ", "ì¹œê·¼í•œ", "ì„¤ëª…í˜•", "ë¶„ì„ì "])  # Korean tone options
    length = st.radio("ê¸¸ì´", ["ì§§ê²Œ", "ë³´í†µ", "ê¸¸ê²Œ"], index=1, horizontal=True)
    language = st.selectbox("ìš”ì•½ ì–¸ì–´", ["í•œêµ­ì–´", "English", "æ—¥æœ¬èª", "ä¸­æ–‡"])

    st.markdown("""
    **Tip**
    - 1ë§Œì ì´ìƒì˜ ê¸´ í…ìŠ¤íŠ¸ëŠ” ìë™ìœ¼ë¡œ ë¶„í• /ë³‘í•©(Map-Reduce) ë°©ì‹ìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.
    - ì—…ë¡œë“œëœ `.txt` íŒŒì¼ë„ ì§€ì›í•©ë‹ˆë‹¤.
    """)

# Input area
col1, col2 = st.columns([2, 1])
with col1:
    input_text = st.text_area(
        "ìš”ì•½í•  í…ìŠ¤íŠ¸ ì…ë ¥",
        height=280,
        placeholder="ì—¬ê¸°ì— ê¸´ í…ìŠ¤íŠ¸ë¥¼ ë¶™ì—¬ë„£ê±°ë‚˜ ì—…ë¡œë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”...",
    )
with col2:
    uploaded = st.file_uploader("ë˜ëŠ” .txt íŒŒì¼ ì—…ë¡œë“œ", type=["txt"])  # simple file support
    if uploaded is not None:
        try:
            file_text = uploaded.read().decode("utf-8", errors="ignore")
            # If user typed too, append a delimiter
            if input_text.strip():
                input_text += "\n\n" + file_text
            else:
                input_text = file_text
        except Exception as e:
            st.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")

# Validate API key
if not api_key:
    st.info("ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì— OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()

# Prepare LLM
llm = ChatOpenAI(model=model_name, temperature=temperature, api_key=api_key)

# Run summarization
summarize_btn = st.button("ğŸš€ ìš”ì•½ ì‹¤í–‰", type="primary")

if summarize_btn:
    if not input_text or not input_text.strip():
        st.warning("ìš”ì•½í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        st.stop()

    # Heuristic: choose map-reduce for long content
    CHAR_THRESHOLD = 8000

    if len(input_text) <= CHAR_THRESHOLD:
        runner = build_single_pass_chain(llm, tone=tone, length=length, language=language)
        with st.spinner("ë‹¨ì¼ íŒ¨ìŠ¤ ìš”ì•½ ì¤‘..."):
            try:
                summary = runner(input_text)
                st.success("ì™„ë£Œ")
                st.subheader("ìš”ì•½ ê²°ê³¼")
                st.write(summary)
            except Exception as e:
                st.error(f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    else:
        # Split and use map-reduce
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=3000,
            chunk_overlap=300,
            separators=["\n\n", "\n", " ", ""],
        )
        chunks = splitter.split_text(input_text)
        docs = [Document(page_content=c) for c in chunks]

        runner = build_map_reduce_chain(llm, tone=tone, length=length, language=language)
        with st.spinner(f"ê¸´ ë¬¸ì„œ ë¶„í• ({len(docs)} ì²­í¬) í›„ ìš”ì•½ ì¤‘..."):
            try:
                summary = runner(docs)
                st.success("ì™„ë£Œ")
                st.subheader("ìš”ì•½ ê²°ê³¼")
                st.write(summary)
            except Exception as e:
                st.error(f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# Footer
st.markdown("---")
st.caption("Built with Streamlit Â· LangChain Â· OpenAI (gpt-4o-mini)")
